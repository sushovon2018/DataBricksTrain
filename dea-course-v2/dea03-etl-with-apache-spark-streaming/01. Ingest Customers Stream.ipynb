{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c192bfd8-8dfe-4d9e-aafb-87cecd864dbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stream Customers Data From Cloud Files to Delta Lake\n",
    "1. Read files from cloud storage using DataStreamReader API\n",
    "1. Transform the dataframe to add the following columns\n",
    "    -   file path: Cloud file path\n",
    "    -   ingestion date: Current Timestamp\n",
    "1. Write the transformed data stream to Delta Lake Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb30f65e-40a1-466d-aaaa-e75b626b4b3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Read files using DataStreamReader API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1587114-30f0-444f-af54-9b072893a9d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType, TimestampType\n",
    "\n",
    "customers_schema = StructType(fields=[StructField(\"customer_id\", IntegerType()),\n",
    "                                     StructField(\"customer_name\", StringType()),\n",
    "                                     StructField(\"date_of_birth\", DateType()),\n",
    "                                     StructField(\"telephone\", StringType()),\n",
    "                                     StructField(\"email\", StringType()),\n",
    "                                     StructField(\"member_since\", DateType()),\n",
    "                                     StructField(\"created_timestamp\", TimestampType())\n",
    "                                    ]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfd012bb-3cd5-4694-a59f-7b61aae7cc23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customers_df = (\n",
    "                    spark.readStream\n",
    "                         .format(\"json\")\n",
    "                         .schema(customers_schema)\n",
    "                         .load(\"/Volumes/gizmobox/landing/operational_data/customers_stream/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cb351d8-0daf-40ab-b953-d9a6c356efe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Transform the dataframe to add the following columns\n",
    "- file path: Cloud file path\n",
    "- ingestion date: Current Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be5a17f3-2eab-433e-9846-00de0169ba96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, col\n",
    "\n",
    "customers_transformed_df = (\n",
    "                                customers_df.withColumn(\"file_path\", col(\"_metadata.file_path\"))\n",
    "                                            .withColumn(\"ingestion_date\", current_timestamp())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "033d5f5f-39cd-4e46-8b81-dc68a6133c99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Write the transformed data stream to Delta Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c99ce57-5a45-4f87-a4a5-42e7ce27aa0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "streaming_query = (\n",
    "                    customers_transformed_df.writeStream\n",
    "                        .format(\"delta\")\n",
    "                        .option(\"checkpointLocation\", \"/Volumes/gizmobox/landing/operational_data/customers_stream/_checkpoint_stream\")\n",
    "                        .toTable(\"gizmobox.bronze.customers_stream\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c70f5f0-031a-418b-b7d6-2ae88d738e99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "streaming_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55cf8a94-4598-494f-9eb5-fd2ef91d60e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM gizmobox.bronze.customers_stream;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7376710650778780,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01. Ingest Customers Stream",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
